{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8d3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a new SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Get SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ba7d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['367855\\t172-in-addr\\tarpa\\t1',\n",
       " '367856\\taddr\\tarpa\\t1',\n",
       " '367857\\tamphic\\tarpa\\t1',\n",
       " '367858\\tbeta\\tarpa\\t1',\n",
       " '367859\\tcallic\\tarpa\\t1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Domains CSV File into an RDD\n",
    "common_crawl_domain_counts = sc.textFile('./crawl/cc-main-limited-domains.csv')\n",
    "\n",
    "common_crawl_domain_counts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7950d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function format an entry\n",
    "def fmt_domain_graph_entry(entry):\n",
    "    # Split the entry on delimiter ('\\t') into site_id, domain, tld, and num_subdomains\n",
    "    site_id, domain, tld, num_subdomains = entry.split('\\t')        \n",
    "    return int(site_id), domain, tld, int(num_subdomains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f9ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(367855, '172-in-addr', 'arpa', 1),\n",
       " (367856, 'addr', 'arpa', 1),\n",
       " (367857, 'amphic', 'arpa', 1),\n",
       " (367858, 'beta', 'arpa', 1),\n",
       " (367859, 'callic', 'arpa', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply `fmt_domain_graph_entry` to the raw data RDD\n",
    "formatted_host_counts = common_crawl_domain_counts.map(lambda x: fmt_domain_graph_entry(x))\n",
    "\n",
    "# Display the first few entries of the new RDD\n",
    "formatted_host_counts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb75dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function extract subdomain count from an entry\n",
    "def extract_subdomain_counts(entry):\n",
    "    # Split the entry on delimiter ('\\t') into site_id, domain, tld, and num_subdomains\n",
    "    site_id, domain, tld, num_subdomains = entry.split('\\t')\n",
    "    \n",
    "    # return ONLY the num_subdomains\n",
    "    return int(num_subdomains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4201477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply `extract_subdomain_counts` to the raw data RDD\n",
    "host_counts = common_crawl_domain_counts.map(lambda x: extract_subdomain_counts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8357146d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 7, 1, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few entries\n",
    "host_counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa284001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the RDD to the sum of subdomains with the reduce function\n",
    "total_host_counts = host_counts.reduce(lambda a, b: a + b)\n",
    "\n",
    "total_host_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562745d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the sparkContext and the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
